# -*- coding: utf-8 -*-
"""web_image_scraper_selenium_python.ipynb

Automatically generated by Colaboratory.

'''
#runs functions to search and collect specified images
search_terms = ['USAA bank posters']

for search_term in search_terms:
    collect_web_img.search_and_download(search_term=search_term, driver_path=collect_web_img.initialize_web_driver())
'''

Original file is located at
    https://colab.research.google.com/drive/1_cBsIXid4PapRF0raf5aq16yBQ2JW31A

useful urls:
------------

https://www.shutterstock.com/search/{query}

https://www.google.com/search?q=google+images+{query}&rlz=1C1CHBF_enUS830US830&sxsrf=ALeKk03SgL8-qRAfeZd1QDzweydJ4MlDgg:1628187781073&source=lnms&tbm=isch&sa=X&ved=2ahUKEwi61sWSwJryAhXNTDABHYhPDpsQ_AUoAXoECAEQAw&biw=1536&bih=722&dpr=1.25
"""
"""
to do list
----------------

"""

# imports
from selenium import *
import selenium
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
import requests
import os
import io
from PIL import Image
import hashlib
import time
import logging
import boto3
from botocore.exceptions import ClientError


class collect_web_img:
    def initialize_web_driver():
        DRIVER_PATH = r"C:\Users\jerem\Desktop\chromedriver.exe"
        service = Service(DRIVER_PATH)
        service.start()
        wd = webdriver.Remote(service.service_url)
        wd.quit()
        return DRIVER_PATH

    def fetch_image_urls(query: str, max_links_to_fetch: int, wd: webdriver, sleep_between_interactions: int = 3):
        def scroll_to_end(wd, scroll_point):
            wd.execute_script(f"window.scrollTo(0, {scroll_point});")
            time.sleep(sleep_between_interactions)

        # to build out python package use input function in search_url variable
        # build the unsplash query
        search_url = f"https://www.google.com/search?q=google+images+{query}&rlz=1C1CHBF_enUS830US830&sxsrf=ALeKk03SgL8-qRAfeZd1QDzweydJ4MlDgg:1628187781073&source=lnms&tbm=isch&sa=X&ved=2ahUKEwi61sWSwJryAhXNTDABHYhPDpsQ_AUoAXoECAEQAw&biw=1536&bih=722&dpr=1.25"
        # load the page
        wd.get(search_url)
        time.sleep(sleep_between_interactions)

        image_urls = set()
        image_count = 0
        number_results = 0

        for i in range(1, 20):
            scroll_to_end(wd, i * 1000)
            time.sleep(5)
            thumb = wd.find_elements_by_css_selector("img")
            time.sleep(5)
            for img in thumb:
                print(img)
                print(img.get_attribute('src'))
                image_urls.add(img.get_attribute('src'))
                image_count = len(image_urls)
                number_results = image_count
                time.sleep(.5)
            print(f"Found: {number_results} search results. Extracting links...")
        return image_urls

    def persist_image(folder_path: str, url: str):
        try:
            headers = {'User-agent': 'Chrome / 64.0.3282.186'}
            image_content = requests.get(url, headers=headers).content

        except Exception as e:
            print(f"ERROR - Could not download {url} - {e}")
        try:
            image_file = io.BytesIO(image_content)
            image = Image.open(image_file).convert('RGB')
            file_path = os.path.join(folder_path, hashlib.sha1(image_content).hexdigest()[:10] + '.jpg')
            with open(file_path, 'wb') as f:
                image.save(f, "JPEG", quality=85)
            print(f"SUCCESS - saved {url} - as {file_path}")
        except Exception as e:
            print(f"ERROR - Could not save {url} - {e}")

    def search_and_download(search_term: str, driver_path: str, target_path='./images-UNSPLASH', number_images=200):
        target_folder = os.path.join(target_path, '_'.join(search_term.lower().split(' ')))
        if not os.path.exists(target_folder):
            os.makedirs(target_folder)
        with webdriver.Chrome(executable_path=driver_path) as wd:
            res = collect_web_img.fetch_image_urls(search_term, number_images, wd=wd, sleep_between_interactions=3)

            for elem in res:
                collect_web_img.persist_image(target_folder, elem)

    def start_search(search_term):
        search_terms = search_term
        for search_term in search_terms:
            collect_web_img.search_and_download(search_term=search_term,
                                                driver_path=collect_web_img.initialize_web_driver())


if __name__ == "__main__":
    collect_web_img.start_search(["Checkers Rallys fast food signs"])